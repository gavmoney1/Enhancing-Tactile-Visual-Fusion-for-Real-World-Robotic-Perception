# MAE-Up specific configuration

model:
  patch_size: 16
  encoder_layers: 12
  encoder_heads: 12
  encoder_dim: 768
  decoder_layers: 8
  decoder_heads: 16
  decoder_dim: 512
  mlp_ratio: 4.0
  dropout: 0.1

encoder:
  embed_dim: 256
  depth: 6
  num_heads: 8
  mlp_ratio: 4.0
  dropout_rate: 0.1

decoder:
  embed_dim: 128
  depth: 4
  num_heads: 4
  mlp_ratio: 4.0
  dropout_rate: 0.1

optimization: # overrides
  learning_rate: 0.0003
  weight_decay: 0.05
  warmup_steps: 2000
  beta1: 0.9
  beta2: 0.95

training:
  # epochs: 100
  batch_size: 16
  seed: 42
  mask_ratio: 0.9  # Center mask = 90% masked, 10% visible

data:
  img_size: 224
  mask_strategy: "center"  # Use center masking instead of random

# Classification-specific settings
classification:
  dropout_rate: 0.3
  classifier_hidden_dim: 512
  use_gelu: true