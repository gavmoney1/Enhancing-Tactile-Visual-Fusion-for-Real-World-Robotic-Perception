# Base configuration for all models
data:

  orig_root: "/bighome/gcmoney/Enhancing-Tactile-Visual-Fusion-for-Real-World-Robotic-Perception/datasets/testdata/shapes"
  mask_root: "/bighome/gcmoney/Enhancing-Tactile-Visual-Fusion-for-Real-World-Robotic-Perception/datasets/testdata/shapes"
  labels_path: "/bighome/gcmoney/Enhancing-Tactile-Visual-Fusion-for-Real-World-Robotic-Perception/datasets/testdata/testdata/labels.txt" # TODO: add label support, not currently implemented
  out_dir: "/bighome/gcmoney/Enhancing-Tactile-Visual-Fusion-for-Real-World-Robotic-Perception/demo_test"

  img_size: 224
  mask_ratio: 0.9  # 90% masked
  
training:
  batch_size: 32  # Reduced for laptop
  epochs: 1
  val_split: 0.10
  test_split: 0.20 # TODO: these vals currently only affect metric report
  seed: 42
  
optimization:
  learning_rate: 5e-5 # was 1e-4
  weight_decay: 1e-5
  warmup_steps: 1000
  
memory:
  enable_mixed_precision: false
  gradient_accumulation_steps: 1
  max_memory_gb: 64  # Adjust based on your laptop
  
models_to_train:
  - "mae_up"
  - "conv_autoencoder"
  - "vit"
  - "swin" 
  - "detr"
  
evaluation:
  save_predictions: true
  num_visualization_samples: 1
